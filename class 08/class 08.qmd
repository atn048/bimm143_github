---
title: "Class 08: Analysis of Breast Cancer Cells"
author: "Amy Nguyen (PID: A18148284)"
toc: true
format: pdf
---

## Background

In today's class we will be employing all the R techniques for data analysis that we have learned thus far - including the machine learning methods of clustering and PCA - to analyze real breast cancer biopsy data. 

## Data Import 

The data is in CSV format:

```{r}
fna.data <- "WisconsinCancer.csv"
```

```{r}
wisc.df <- data.frame(fna.data, row.names=1)
```

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
```

wee peak at the data
```{r}
head(wisc.df, 3)
```

> Q1. How many observations are in this dataset? 569 observations.

```{r}
nrow(wisc.df)
```

> Q2. How many of the observations have a malignant diagnosis? 212 observations.

```{r}
sum( wisc.df$diagnosis == "M" )
```

```{r}
table( wisc.df$diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean? 10 variables

```{r}
head(wisc.df)
```

```{r}
length(grep("_mean", colnames(wisc.df), value=T))
```
```{r}
colnames(wisc.df)
```
We need to remove the `diagnosis` column before we do any further analysis of this data set - we don't want to pass this to PCA etc. We will save it as a separate wee vector that we can use later to compare our findings to those experts.

```{r}
wisc.data <- wisc.df[,-1]
diagnosis <- wisc.df$diagnosis
```

## Principal Component Analysis (PCA)

The main function in base R is called `prcomp()` we will use the optional argument `scale=TRUE` here as the data columns/features/dimensions are on very different scales in the original data set.

```{r}
colMeans(wisc.data)
apply(wisc.data,2,sd)
```

```{r}
wisc.pr <- prcomp(wisc.data, scale=T)
```

```{r}
summary(wisc.pr)
```
> Q4. From your results, what proportion of the original variance is captured by the frist principal component (PC1)? 44.27%

> Q5. How many principal componetns (PCs) are required to describe at least 70% of the original variance in the data? 3 PCs

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data? 7 PCs

```{r}
attributes(wisc.pr) 
```

```{r}
biplot(wisc.pr)
```
> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why? The plot is extremely poor for visual interpretation and difficult to understand because the row names are plotted which obsecures the data points.

```{r}
library(ggplot2)
ggplot(wisc.pr$x) +
  aes(PC1, PC2, col=diagnosis) +
  geom_point()
```
> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots? These plots show how PC1 succesfully captures the visual distinction between the benign (red data points) and malignant (blue data points) cancer samples. 

```{r}
ggplot(wisc.pr$x) +
  aes(PC1, PC3, col=diagnosis) +
  geom_point()
```

Calculate variance of each component
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```
Variance explained by each principal component: pve
```{r}
pve <- pr.var / sum(pr.var)
```
Plot variance explained for each principal component 
```{r}
plot(c(1,pve), xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
Alternative scree plot of the same data, note data driven y-axis
```{r}
barplot(pve, ylab = "Percent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
library(factoextra)
```
```{r}
fviz_eig(wisc.pr, addlabels = TRUE)
```
```{r}
wisc.pr$rotation["concave.points_mean", 1]
pc1_contributions <- wisc.pr$rotation[, 1]
abs(pc1_contributions) > abs(pc1_contributions["concave.points_mean"])
```

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC. Are there any features with larger contributions than this one? The component of the loading vector for the feature concave.points_mean is -0.26. There are no features with larger contributions. 

## Hierarchial Clustering

The goal of this section is to do hierarchical clustering of the original data to see if there is any obvious grouping into malignant and benign clusters.

In short, these results are not good!

First we will scale our `wisc.data` 

```{r}
data.scaled <- scale(wisc.data)
```
```{r}
data.dist <- dist(data.scaled)
```

```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
```

> Q10. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters? At height = 11

```{r}
plot(wisc.hclust)
abline(h = 11, col="red", lty=2)
```
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.hclust.clusters, diagnosis)
```


> Q12. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning. The ward.D2 method gives my favorite result. It produces the most well-separated clusters as it minimizes the within-cluster variance. 

## Combining Methods 

The idea here is that I can take my new variables (i.e. the scores on the PCs `wisc.pr$x`) that are better descriptors of the data-set than the original features (i.e. the 30 columns in `wisc.data`) and use these as a basis for the clustering. 

```{r}
pc.dist <- dist(wisc.pr$x[ ,1:3])
wisc.pr.hclust <- hclust(pc.dist, method = "ward.D2")
plot(wisc.pr.hclust)
```
```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
table(wisc.pr.hclust.clusters)
```
```{r}
table(diagnosis)
```
> Q13. How well does the newly created hclust model with two clusters separate out the two “M” and “B” diagnoses?

I can now run `table()` with both my clustering `wisc.pr.hclust.clusters` and the expert `diagnoses`
```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```
Our cluster "1" has 179 "M" diagnosis
Our cluster "2" has 333 "B" diagnosis

179 TP
24 FP
333 TN 
33 FN

> Q14. How well do the hierarchical clustering models you created in the previous sections (i.e. without first doing PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.hclust.clusters and wisc.pr.hclust.clusters) with the vector containing the actual diagnoses. The wisc.hclust.clusters model did worse at separating diagnoses compared to the wisc.pr.hclust.clusters model. 

```{r}
table(wisc.hclust.clusters, diagnosis)
table(wisc.pr.hclust.clusters, diagnosis)
```

## Sensitivity/Specificity 

Sensitivity: TP/(TP+FN)
```{r}
179/(179+33)
```

Specificity: TN/(TN+FP)
```{r}
333/(333+24)
```

> Q15. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity? The model based on PCA-transsofrmed data resulted in the best specificity (93%) and sensitivity (84%). 

## Prediction 
We can use our PCA model for prediction of new unseen cases. 

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```
```{r}
plot(wisc.pr$x[,1:2], col=wisc.pr.hclust.clusters)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
> Q16. Which of these new patients should we prioritize for follow up based on your results? We should prioritize patient 2 for follow up. 
